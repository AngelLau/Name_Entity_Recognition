{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "from collections import defaultdict, namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANY_SPACE = '<SPACE>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metrics = namedtuple('Metrics', 'tp fp fn prec rec fscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalCounts(object):\n",
    "    def __init__(self):\n",
    "        self.correct_chunk = 0    # number of correctly identified chunks\n",
    "        self.correct_tags = 0     # number of correct chunk tags\n",
    "        self.found_correct = 0    # number of chunks in corpus\n",
    "        self.found_guessed = 0    # number of identified chunks\n",
    "        self.token_counter = 0    # token counter (ignores sentence breaks)\n",
    "\n",
    "        # counts by type\n",
    "        self.t_correct_chunk = defaultdict(int)\n",
    "        self.t_found_correct = defaultdict(int)\n",
    "        self.t_found_guessed = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(argv):\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='evaluate tagging results using CoNLL criteria',\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "    arg = parser.add_argument\n",
    "    arg('-b', '--boundary', metavar='STR', default='-X-',\n",
    "        help='sentence boundary')\n",
    "    arg('-d', '--delimiter', metavar='CHAR', default=ANY_SPACE,\n",
    "        help='character delimiting items in input')\n",
    "    arg('-o', '--otag', metavar='CHAR', default='O',\n",
    "        help='alternative outside tag')\n",
    "    arg('file', nargs='?', default=None)\n",
    "    return parser.parse_args(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tag(t):\n",
    "    m = re.match(r'^([^-]*)-(.*)$', t)\n",
    "    return m.groups() if m else (t, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(iterable, options=None):\n",
    "    if options is None:\n",
    "        options = parse_args([])    # use defaults\n",
    "\n",
    "    counts = EvalCounts()\n",
    "    num_features = None       # number of features per line\n",
    "    in_correct = False        # currently processed chunks is correct until now\n",
    "    last_correct = 'O'        # previous chunk tag in corpus\n",
    "    last_correct_type = ''    # type of previously identified chunk tag\n",
    "    last_guessed = 'O'        # previously identified chunk tag\n",
    "    last_guessed_type = ''    # type of previous chunk tag in corpus\n",
    "\n",
    "    for line in iterable:\n",
    "        line = line.rstrip('\\r\\n')\n",
    "\n",
    "        if options.delimiter == ANY_SPACE:\n",
    "            features = line.split()\n",
    "        else:\n",
    "            features = line.split(options.delimiter)\n",
    "\n",
    "        if num_features is None:\n",
    "            num_features = len(features)\n",
    "        elif num_features != len(features) and len(features) != 0:\n",
    "            raise FormatError('unexpected number of features: %d (%d)' %\n",
    "                              (len(features), num_features))\n",
    "\n",
    "        if len(features) == 0 or features[0] == options.boundary:\n",
    "            features = [options.boundary, 'O', 'O']\n",
    "        if len(features) < 3:\n",
    "            raise FormatError('unexpected number of features in line %s' % line)\n",
    "\n",
    "        guessed, guessed_type = parse_tag(features.pop())\n",
    "        correct, correct_type = parse_tag(features.pop())\n",
    "        first_item = features.pop(0)\n",
    "\n",
    "        if first_item == options.boundary:\n",
    "            guessed = 'O'\n",
    "\n",
    "        end_correct = end_of_chunk(last_correct, correct,\n",
    "                                   last_correct_type, correct_type)\n",
    "        end_guessed = end_of_chunk(last_guessed, guessed,\n",
    "                                   last_guessed_type, guessed_type)\n",
    "        start_correct = start_of_chunk(last_correct, correct,\n",
    "                                       last_correct_type, correct_type)\n",
    "        start_guessed = start_of_chunk(last_guessed, guessed,\n",
    "                                       last_guessed_type, guessed_type)\n",
    "\n",
    "        if in_correct:\n",
    "            if (end_correct and end_guessed and\n",
    "                last_guessed_type == last_correct_type):\n",
    "                in_correct = False\n",
    "                counts.correct_chunk += 1\n",
    "                counts.t_correct_chunk[last_correct_type] += 1\n",
    "            elif (end_correct != end_guessed or guessed_type != correct_type):\n",
    "                in_correct = False\n",
    "\n",
    "        if start_correct and start_guessed and guessed_type == correct_type:\n",
    "            in_correct = True\n",
    "\n",
    "        if start_correct:\n",
    "            counts.found_correct += 1\n",
    "            counts.t_found_correct[correct_type] += 1\n",
    "        if start_guessed:\n",
    "            counts.found_guessed += 1\n",
    "            counts.t_found_guessed[guessed_type] += 1\n",
    "        if first_item != options.boundary:\n",
    "            if correct == guessed and guessed_type == correct_type:\n",
    "                counts.correct_tags += 1\n",
    "            counts.token_counter += 1\n",
    "\n",
    "        last_guessed = guessed\n",
    "        last_correct = correct\n",
    "        last_guessed_type = guessed_type\n",
    "        last_correct_type = correct_type\n",
    "\n",
    "    if in_correct:\n",
    "        counts.correct_chunk += 1\n",
    "        counts.t_correct_chunk[last_correct_type] += 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniq(iterable):\n",
    "  seen = set()\n",
    "  return [i for i in iterable if not (i in seen or seen.add(i))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(correct, guessed, total):\n",
    "    tp, fp, fn = correct, guessed-correct, total-correct\n",
    "    p = 0 if tp + fp == 0 else 1.*tp / (tp + fp)\n",
    "    r = 0 if tp + fn == 0 else 1.*tp / (tp + fn)\n",
    "    f = 0 if p + r == 0 else 2 * p * r / (p + r)\n",
    "    return Metrics(tp, fp, fn, p, r, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(counts):\n",
    "    c = counts\n",
    "    overall = calculate_metrics(\n",
    "        c.correct_chunk, c.found_guessed, c.found_correct\n",
    "    )\n",
    "    by_type = {}\n",
    "    for t in uniq(c.t_found_correct.keys() + c.t_found_guessed.keys()):\n",
    "        by_type[t] = calculate_metrics(\n",
    "            c.t_correct_chunk[t], c.t_found_guessed[t], c.t_found_correct[t]\n",
    "        )\n",
    "    return overall, by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(counts, out=None):\n",
    "    if out is None:\n",
    "        out = sys.stdout\n",
    "\n",
    "    overall, by_type = metrics(counts)\n",
    "\n",
    "    c = counts\n",
    "    out.write('processed %d tokens with %d phrases; ' %\n",
    "              (c.token_counter, c.found_correct))\n",
    "    out.write('found: %d phrases; correct: %d.\\n' %\n",
    "              (c.found_guessed, c.correct_chunk))\n",
    "\n",
    "    if c.token_counter > 0:\n",
    "        out.write('accuracy: %6.2f%%; ' %\n",
    "                  (100.*c.correct_tags/c.token_counter))\n",
    "        out.write('precision: %6.2f%%; ' % (100.*overall.prec))\n",
    "        out.write('recall: %6.2f%%; ' % (100.*overall.rec))\n",
    "        out.write('FB1: %6.2f\\n' % (100.*overall.fscore))\n",
    "\n",
    "    for i, m in sorted(by_type.items()):\n",
    "        out.write('%17s: ' % i)\n",
    "        out.write('precision: %6.2f%%; ' % (100.*m.prec))\n",
    "        out.write('recall: %6.2f%%; ' % (100.*m.rec))\n",
    "        out.write('FB1: %6.2f  %d\\n' % (100.*m.fscore, c.t_found_guessed[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_of_chunk(prev_tag, tag, prev_type, type_):\n",
    "    # check if a chunk ended between the previous and current word\n",
    "    # arguments: previous and current chunk tags, previous and current types\n",
    "    chunk_end = False\n",
    "\n",
    "    if prev_tag == 'E': chunk_end = True\n",
    "    if prev_tag == 'S': chunk_end = True\n",
    "\n",
    "    if prev_tag == 'B' and tag == 'B': chunk_end = True\n",
    "    if prev_tag == 'B' and tag == 'S': chunk_end = True\n",
    "    if prev_tag == 'B' and tag == 'O': chunk_end = True\n",
    "    if prev_tag == 'I' and tag == 'B': chunk_end = True\n",
    "    if prev_tag == 'I' and tag == 'S': chunk_end = True\n",
    "    if prev_tag == 'I' and tag == 'O': chunk_end = True\n",
    "\n",
    "    if prev_tag != 'O' and prev_tag != '.' and prev_type != type_:\n",
    "        chunk_end = True\n",
    "\n",
    "    # these chunks are assumed to have length 1\n",
    "    if prev_tag == ']': chunk_end = True\n",
    "    if prev_tag == '[': chunk_end = True\n",
    "\n",
    "    return chunk_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_of_chunk(prev_tag, tag, prev_type, type_):\n",
    "    # check if a chunk started between the previous and current word\n",
    "    # arguments: previous and current chunk tags, previous and current types\n",
    "    chunk_start = False\n",
    "\n",
    "    if tag == 'B': chunk_start = True\n",
    "    if tag == 'S': chunk_start = True\n",
    "\n",
    "    if prev_tag == 'E' and tag == 'E': chunk_start = True\n",
    "    if prev_tag == 'E' and tag == 'I': chunk_start = True\n",
    "    if prev_tag == 'S' and tag == 'E': chunk_start = True\n",
    "    if prev_tag == 'S' and tag == 'I': chunk_start = True\n",
    "    if prev_tag == 'O' and tag == 'E': chunk_start = True\n",
    "    if prev_tag == 'O' and tag == 'I': chunk_start = True\n",
    "\n",
    "    if tag != 'O' and tag != '.' and prev_type != type_:\n",
    "        chunk_start = True\n",
    "\n",
    "    # these chunks are assumed to have length 1\n",
    "    if tag == '[': chunk_start = True\n",
    "    if tag == ']': chunk_start = True\n",
    "\n",
    "    return chunk_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    args = parse_args(argv[1:])\n",
    "\n",
    "    if args.file is None:\n",
    "        counts = evaluate(sys.stdin, args)\n",
    "    else:\n",
    "        with open(args.file) as f:\n",
    "            counts = evaluate(f, args)\n",
    "    report(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-b STR] [-d CHAR] [-o CHAR] [file]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: g _ i o b 2 . o u t p u t\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angel/miniconda3/envs/python2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2886: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    sys.exit(main('eng_iob2.output'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
